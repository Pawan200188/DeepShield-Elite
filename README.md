
# DeepShield-Elite

**Project Description:**

This project is an AI-powered system designed to detect DeepFakes‚Äîrealistic but fake videos and images created using artificial intelligence. In today‚Äôs digital world, where people regularly consume media from social platforms, news websites, and other online sources, the threat of DeepFakes is growing rapidly. While such technology can be used for positive purposes, it is often misused to spread misinformation, harm reputations, or commit fraud.

Our solution works by analyzing videos frame by frame to detect signs of manipulation such as unnatural facial expressions, inconsistent lighting, or unusual textures. This approach allows the system to catch subtle details that may go unnoticed when viewing entire videos. By breaking down videos into individual frames and studying them closely, the system becomes more accurate and reliable in identifying fake content.

This project is aimed at media agencies, law enforcement, legal institutions, content verification platforms, and anyone who needs to ensure the authenticity of digital media. It helps protect individuals and organizations from falling victim to false information, fraud, or digital impersonation, promoting a safer and more trustworthy online environment.



## Table of Contents:
1.What is DeepFake?

2.Demo of the Project

3.Impact of DeepFake Videos/Image

4.Project Objectives

5.Project Pipeline

6.Pre-processing WorkFlow

7.Prediction WorkFlow

8.Models Usage and their Architecture

9.Code Running Commands

10.Technologies Used

11.Conclusion

12.Team
## What is Deep Fake?
1.DeepFake is AI-generated fake content designed to look real.

2.It uses deep learning to manipulate faces, voices, or actions.

3.DeepFakes can create highly realistic videos or images.

4.They are often used to spread misinformation or commit fraud.

5.Detecting DeepFakes is difficult without advanced AI tools.


## Demo of the Project
Video link-https://youtu.be/w91nRclZUDE?si=mRuoT65vjQLvOHcV
## Impact of DeepFake:
1.Misinformation & Erosion of Trust

Deepfakes spread fake news, political propaganda, and misleading content.

2.Personal & Social Harm
Victims can face defamation, harassment, and psychological trauma (e.g., deepfake porn, fake criminal footage).

3.Threats to Security & Law
Used in cybercrimes, blackmail, and impersonation for fraud (e.g., voice cloning of CEOs).


4.Impact on Business & Politics
Fake content can harm brand reputation, manipulate stock markets, or influence elections.



## Project Objectives
üéØ Project Objective:
The primary objective of this project is to design and develop an AI-powered Deepfake Detection Tool capable of accurately identifying manipulated digital content in both videos and images. In an age where deepfakes pose serious threats to privacy, security, media integrity, and public trust, our goal is to contribute a solution that empowers individuals and organizations to verify content authenticity with ease and reliability.

This project aims to:

(1). Detect Deepfakes in Visual Media (Images & Videos):
Utilize a hybrid deep learning approach that combines Convolutional Neural Networks (CNNs) for spatial feature extraction and Long Short-Term Memory (LSTM) networks for capturing temporal dependencies in video frames. This architecture allows the system to efficiently analyze single image frames as well as frame sequences in videos to identify signs of manipulation.

(2). Automate the Frame Analysis Workflow:
Leverage Kaggle-based datasets containing both real and fake media. For videos, individual frames are extracted and passed through the detection model. For images, a single frame is directly analyzed. This streamlined process ensures consistent and scalable evaluation across various input types.


(3). Implement a Robust Deep Learning Model:
Use PyTorch to build and train the model, integrating advanced techniques in computer vision and sequence modeling. The model is designed to detect artifacts, facial inconsistencies, and unnatural pixel patterns often present in AI-generated content.

(4). Evaluate Model Performance with Real Metrics:
Incorporate key evaluation metrics such as Accuracy, Precision, Recall, and F1-Score, calculated using Scikit-learn. Additionally, the system generates a confusion matrix for detailed performance analysis, helping users understand the model‚Äôs reliability.

(5). Provide a User-Friendly Interface:
Develop a clean and responsive web-based platform using HTML, CSS, and JavaScript, allowing users to upload images or videos for analysis. The backend, built using Flask, handles file input, model interaction, and result delivery seamlessly.

(6). Contribute to Digital Safety and Misinformation Control:
Offer this tool as a potential aid for content creators, journalists, fact-checkers, legal authorities, and the general public to validate the authenticity of digital content. Our broader mission is to promote ethical AI and support responsible content consumption in the digital era.

In summary, the tool is designed to bridge cutting-edge AI with practical usability ‚Äî enabling everyday users to detect fake media effortlessly, while also demonstrating the power and potential of student-led innovation in addressing real-world problems.
## Project Pipeline
Data Collection: Collected image and video deepfake datasets from Kaggle for training and testing.

Preprocessing: Extracted and resized video frames using OpenCV and processed images with Pillow.

Model Building: Developed a CNN‚ÄìLSTM hybrid model using PyTorch to detect spatial and temporal inconsistencies.

Training & Evaluation: Trained the model and evaluated it using Accuracy, Precision, Recall, F1 Score, and Confusion Matrix via Scikit-learn.

Backend Development: Implemented Flask to handle file uploads, process data, and connect the model to the interface.

Frontend Design: Built a user-friendly interface using HTML, CSS, and JavaScript for uploading media and displaying results.

Integration & Testing: Integrated the system end-to-end and tested it for real-time image and video deepfake detection.

## Pre-processing WorkFlow
üéûÔ∏è Video to Frame Conversion Process
To perform deepfake detection on videos, each video is first converted into a series of image frames. The following steps outline the frame extraction pipeline implemented using OpenCV:

üîÑ Workflow Steps:
1. Load the Video File

    The video is loaded using cv2.VideoCapture().

2. Check if the Video is Opened Successfully

    If not, the process exits or throws an error.

    If yes, it proceeds to frame counting.

3. Count Total Number of Frames

    Retrieves the total frame count using cap.get(cv2.CAP_PROP_FRAME_COUNT).

4. Generate Frame Indices

    A list of frame indices is generated to specify which frames to extract (e.g., every nth frame).

5. Iterate Through Selected Frames

Loop through each frame index:

    Set the video to the current frame position using cap.set().

    Read the frame using cap.read().

6. Verify Each Frame Read

If the frame is read successfully:

    Convert from BGR (OpenCV default) to RGB format using cv2.cvtColor().

    Resize the frame to a fixed input size (e.g., 224√ó224).

    Store the processed frame in a list.

If the frame read fails:

    Handle the failure gracefully (log and skip the frame).

7. Return the List of Processed Frames

    After all frames are processed, return the list for model inference or further processing.

Libraries Used:

cv2 (OpenCV) ‚Äì For video handling and frame extraction

Pillow ‚Äì Optional for image operations

torch ‚Äì For converting frames to tensors for model input
## Prediction WorkFlow
1. Receive Input

    User uploads either an image or video through the web interface.

2. Preprocess Input

If the input is a video:

    Extract and preprocess frames (as described in the Video to Frame Conversion Process).

If the input is an image:

    Load, resize, normalize, and convert to tensor.

All inputs are transformed into PyTorch-compatible tensors.

3. Model Inference

The preprocessed input is passed to the trained deep learning model.

CNN + LSTM hybrid architecture is used:

    CNN extracts spatial features.

    LSTM captures temporal dependencies across frames (for videos).

4. Get Prediction Output

The model returns a probability or class score.

    Output is binary:

    0 ‚Üí Real

    1 ‚Üí Fake

5. Postprocess Result

    Convert the raw output into a human-readable label ("Real" or "Fake").

    Optionally include the confidence score or probability.

6. Display Result to User

    The frontend receives the result via the Flask backend and displays it on the web interface.
## Models Usage and their Architecture

Our Deepfake Detection Tool employs a hybrid deep learning approach that combines Convolutional Neural Networks (CNNs) with Long Short-Term Memory (LSTM) networks to accurately detect manipulated content in both images and videos. For video analysis, the model first extracts individual frames, and each frame is passed through a CNN that captures important spatial features. These features, representing visual patterns in each frame, are then fed into an LSTM network which analyzes the sequence of features over time. This combination enables the model to understand both spatial and temporal inconsistencies that often arise in deepfaked videos. For image-based detection, a standalone CNN architecture is used. The image is passed through several convolutional and pooling layers followed by fully connected layers to produce a binary classification‚Äîeither "Real" or "Fake".

The models are built using PyTorch, with additional help from libraries like OpenCV (cv2) for video frame extraction and Pillow for image loading. The outputs are evaluated using metrics such as accuracy, precision, recall, F1-score, and confusion matrix, calculated using scikit-learn. This architecture was chosen because CNNs are highly effective at extracting visual features, while LSTMs are ideal for learning sequential dependencies, making the combined model especially powerful for temporal content like video. This deep learning-based strategy provides a robust solution for detecting subtle manipulations in multimedia content, supporting the goal of ensuring digital content integrity.

## Code Running Commands

uvicorn main:app --reload

pip install Pytorch
pip install pillow
pip install scikit-learn




## Technologies Used

1. PyTorch ‚Äì For building and training deep learning models.

2. Torchvision ‚Äì For image transformations and model support.

3. scikit-learn ‚Äì For evaluation metrics like accuracy, precision, recall, and F1-score.

4. OpenCV (cv2) ‚Äì For video frame extraction and image manipulation.

5. Pillow (PIL) ‚Äì For loading and preprocessing image data.

6. NumPy ‚Äì For array and tensor operations.

7. Flask ‚Äì Backend framework to handle model inference and API routes.

8. HTML, CSS, JavaScript ‚Äì For designing the frontend user interface.

9. Jupyter Notebook / Python Scripts ‚Äì For model development and testing.

 10. Git ‚Äì For version control and team collaboration.

 11. Kaggle ‚Äì Source for publicly available deepfake video/image datasets.


## Conclusion
In an era where manipulated digital content is increasingly difficult to detect, our Deepfake Detection Tool provides a practical and effective solution for identifying forged images and videos. By leveraging a hybrid deep learning architecture combining CNN and LSTM, along with powerful libraries like PyTorch, OpenCV, and Flask, we have built a system that can analyze spatial and temporal patterns to classify content as real or fake with high accuracy. The tool is designed to be user-friendly and scalable, making it suitable for applications in journalism, legal forensics, content moderation, and public safety. We believe this project is a small but meaningful step toward fostering trust and authenticity in digital media.


## Team
    @SnehalDnyane
    @Poras2005
